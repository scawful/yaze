<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.8"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>yaze: LLM Integration: Executive Summary &amp; Getting Started</title>
<link href="../../tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript">var page_layout=1;</script>
<script type="text/javascript" src="../../jquery.js"></script>
<script type="text/javascript" src="../../dynsections.js"></script>
<link href="../../navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../resize.js"></script>
<script type="text/javascript" src="../../navtreedata.js"></script>
<script type="text/javascript" src="../../navtree.js"></script>
<link href="../../search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../search/searchdata.js"></script>
<script type="text/javascript" src="../../search/search.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
  $(document).ready(function() { init_search(); });
/* @license-end */
</script>
<link href="../../doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="side-nav" class="ui-resizable side-nav-resizable"><!-- do not remove this div, it is closed by doxygen! -->
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectlogo"><img alt="Logo" src="../../yaze.ico"/></td>
  <td id="projectalign">
   <div id="projectname">yaze<span id="projectnumber">&#160;0.3.1</span>
   </div>
   <div id="projectbrief">Link to the Past ROM Editor</div>
  </td>
 </tr>
   <tr><td colspan="2">        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <span id="MSearchSelect"                onmouseover="return searchBox.OnSearchSelectShow()"                onmouseout="return searchBox.OnSearchSelectHide()">&#160;</span>
          <input type="text" id="MSearchField" value="" placeholder="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="../../search/close.svg" alt=""/></a>
          </span>
        </div>
</td></tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.8 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "../../search/",'.html');
/* @license-end */
</script>
</div><!-- top -->
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(document).ready(function(){initNavTree('d5/d60/md_docs_2z3ed_2LLM-INTEGRATION-SUMMARY.html','../../'); initResizable(); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div><div class="header">
  <div class="headertitle"><div class="title">LLM Integration: Executive Summary &amp; Getting Started</div></div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p><a class="anchor" id="autotoc_md1659"></a> <b>Date</b>: October 3, 2025 <br  />
 <b>Author</b>: GitHub Copilot <br  />
 <b>Status</b>: Ready to Implement</p>
<h1><a class="anchor" id="autotoc_md1660"></a>
What Changed?</h1>
<p>After reviewing the z3ed CLI design and implementation plan, we've <b>deprioritized IT-10 (Collaborative Editing)</b> in favor of <b>practical LLM integration</b>. This is the critical next step to make the agentic workflow system production-ready.</p>
<h1><a class="anchor" id="autotoc_md1661"></a>
Why This Matters</h1>
<p>The z3ed infrastructure is <b>already complete</b>:</p><ul>
<li>✅ Resource-oriented CLI with comprehensive commands</li>
<li>✅ Proposal-based workflow with sandbox execution</li>
<li>✅ Machine-readable API catalogue (<code>z3ed-resources.yaml</code>)</li>
<li>✅ GUI automation harness for verification</li>
<li>✅ ProposalDrawer for human review</li>
</ul>
<p><b>What's missing</b>: Real LLM integration to turn prompts into actions.</p>
<p>Currently, <code>z3ed agent run</code> uses <code>MockAIService</code> which returns hardcoded test commands. We need to connect real LLMs (Ollama, Gemini, Claude) to make the agent system useful.</p>
<h1><a class="anchor" id="autotoc_md1662"></a>
What You Get</h1>
<p>After implementing this plan, users will be able to:</p>
<div class="fragment"><div class="line"># Install Ollama (one-time setup)</div>
<div class="line">brew install ollama</div>
<div class="line">ollama serve &amp;</div>
<div class="line">ollama pull qwen2.5-coder:7b</div>
<div class="line"> </div>
<div class="line"># Configure z3ed</div>
<div class="line">export YAZE_AI_PROVIDER=ollama</div>
<div class="line"> </div>
<div class="line"># Use natural language to modify ROMs</div>
<div class="line">z3ed agent run \</div>
<div class="line">  --prompt &quot;Make all soldier armor red&quot; \</div>
<div class="line">  --rom zelda3.sfc \</div>
<div class="line">  --sandbox</div>
<div class="line"> </div>
<div class="line"># Review generated commands</div>
<div class="line">z3ed agent diff</div>
<div class="line"> </div>
<div class="line"># Accept changes</div>
<div class="line"># (Open YAZE GUI → Debug → Agent Proposals → Review → Accept)</div>
</div><!-- fragment --><p>The LLM will automatically:</p><ol type="1">
<li>Parse the natural language prompt</li>
<li>Generate appropriate <code>z3ed</code> commands</li>
<li>Execute them in a sandbox</li>
<li>Present results for human review</li>
</ol>
<h1><a class="anchor" id="autotoc_md1663"></a>
Implementation Roadmap</h1>
<h2><a class="anchor" id="autotoc_md1664"></a>
Phase 1: Ollama Integration (4-6 hours) 🎯 START HERE</h2>
<p><b>Priority</b>: Highest <br  />
 <b>Why First</b>: Local, free, no API keys, fast iteration</p>
<p><b>Deliverables</b>:</p><ul>
<li><code>OllamaAIService</code> class with health checks</li>
<li>CMake integration for httplib</li>
<li>Service selection mechanism (env vars)</li>
<li>End-to-end test script</li>
</ul>
<p><b>Key Files</b>:</p><ul>
<li><code>src/cli/service/ollama_ai_service.{h,cc}</code> (new)</li>
<li><code><a class="el" href="../../d9/d8d/general__commands_8cc.html">src/cli/handlers/agent/general_commands.cc</a></code> (update)</li>
<li><code>CMakeLists.txt</code> (add httplib support)</li>
</ul>
<h2><a class="anchor" id="autotoc_md1665"></a>
Phase 2: Gemini Fixes (2-3 hours)</h2>
<p><b>Deliverables</b>:</p><ul>
<li>Fix existing <code>GeminiAIService</code> implementation</li>
<li>Better prompting with resource catalogue</li>
<li>Markdown code block stripping</li>
</ul>
<h2><a class="anchor" id="autotoc_md1666"></a>
Phase 3: Claude Integration (2-3 hours)</h2>
<p><b>Deliverables</b>:</p><ul>
<li><code>ClaudeAIService</code> class</li>
<li>Messages API integration</li>
<li>Same interface as other services</li>
</ul>
<h2><a class="anchor" id="autotoc_md1667"></a>
Phase 4: Enhanced Prompting (3-4 hours)</h2>
<p><b>Deliverables</b>:</p><ul>
<li><code>PromptBuilder</code> utility class</li>
<li>Resource catalogue integration</li>
<li>Few-shot examples</li>
<li>Context injection (ROM state)</li>
</ul>
<h1><a class="anchor" id="autotoc_md1668"></a>
Quick Start (After Implementation)</h1>
<h2><a class="anchor" id="autotoc_md1669"></a>
For Developers (Implement Now)</h2>
<ol type="1">
<li><b>Read the implementation plan</b>:<ul>
<li><a class="el" href="../../de/da5/md_docs_2z3ed_2LLM-INTEGRATION-PLAN.html">LLM-INTEGRATION-PLAN.md</a> - Complete technical guide</li>
<li><a class="el" href="../../d2/d74/md_docs_2z3ed_2LLM-IMPLEMENTATION-CHECKLIST.html">LLM-IMPLEMENTATION-CHECKLIST.md</a> - Step-by-step tasks</li>
</ul>
</li>
<li><b>Start with Phase 1</b>: <div class="fragment"><div class="line"># Follow checklist in LLM-IMPLEMENTATION-CHECKLIST.md</div>
<div class="line"># Implementation time: ~4-6 hours</div>
</div><!-- fragment --></li>
<li><b>Test as you go</b>: <div class="fragment"><div class="line"># Run quickstart script when ready</div>
<div class="line">./scripts/quickstart_ollama.sh</div>
</div><!-- fragment --></li>
</ol>
<h2><a class="anchor" id="autotoc_md1670"></a>
For End Users (After Development)</h2>
<ol type="1">
<li><b>Install Ollama</b>: <div class="fragment"><div class="line">brew install ollama  # macOS</div>
<div class="line">ollama serve &amp;</div>
<div class="line">ollama pull qwen2.5-coder:7b</div>
</div><!-- fragment --></li>
<li><b>Configure z3ed</b>: <div class="fragment"><div class="line">export YAZE_AI_PROVIDER=ollama</div>
</div><!-- fragment --></li>
<li><b>Try it out</b>: <div class="fragment"><div class="line">z3ed agent run --prompt &quot;Validate my ROM&quot; --rom zelda3.sfc</div>
</div><!-- fragment --></li>
</ol>
<h1><a class="anchor" id="autotoc_md1671"></a>
Alternative Providers</h1>
<h2><a class="anchor" id="autotoc_md1672"></a>
Gemini (Remote, API Key Required)</h2>
<div class="fragment"><div class="line">export GEMINI_API_KEY=your_key_here</div>
<div class="line">export YAZE_AI_PROVIDER=gemini</div>
<div class="line">z3ed agent run --prompt &quot;...&quot;</div>
</div><!-- fragment --><h2><a class="anchor" id="autotoc_md1673"></a>
Claude (Remote, API Key Required)</h2>
<div class="fragment"><div class="line">export CLAUDE_API_KEY=your_key_here</div>
<div class="line">export YAZE_AI_PROVIDER=claude</div>
<div class="line">z3ed agent run --prompt &quot;...&quot;</div>
</div><!-- fragment --><h1><a class="anchor" id="autotoc_md1674"></a>
Documentation Structure</h1>
<div class="fragment"><div class="line">docs/z3ed/</div>
<div class="line">├── README.md                           # Overview + navigation</div>
<div class="line">├── E6-z3ed-cli-design.md               # Architecture &amp; design</div>
<div class="line">├── E6-z3ed-implementation-plan.md      # Overall roadmap</div>
<div class="line">├── LLM-INTEGRATION-PLAN.md             # 📋 Detailed LLM guide (NEW)</div>
<div class="line">├── LLM-IMPLEMENTATION-CHECKLIST.md     # ✅ Step-by-step tasks (NEW)</div>
<div class="line">└── LLM-INTEGRATION-SUMMARY.md          # 📄 This file (NEW)</div>
<div class="line"> </div>
<div class="line">scripts/</div>
<div class="line">└── quickstart_ollama.sh                # 🚀 Automated setup test (NEW)</div>
</div><!-- fragment --><h1><a class="anchor" id="autotoc_md1675"></a>
Key Architectural Decisions</h1>
<h2><a class="anchor" id="autotoc_md1676"></a>
1. Service Interface Pattern</h2>
<p>All LLM providers implement the same <code>AIService</code> interface:</p>
<div class="fragment"><div class="line"><span class="keyword">class </span>AIService {</div>
<div class="line"> <span class="keyword">public</span>:</div>
<div class="line">  <span class="keyword">virtual</span> absl::StatusOr&lt;std::vector&lt;std::string&gt;&gt; GetCommands(</div>
<div class="line">      <span class="keyword">const</span> std::string&amp; prompt) = 0;</div>
<div class="line">};</div>
</div><!-- fragment --><p>This allows easy swapping between Ollama, Gemini, Claude, or Mock.</p>
<h2><a class="anchor" id="autotoc_md1677"></a>
2. Environment-Based Selection</h2>
<p>Provider selection via environment variables (not compile-time):</p>
<div class="fragment"><div class="line">export YAZE_AI_PROVIDER=ollama  # or gemini, claude, mock</div>
</div><!-- fragment --><p>This enables:</p><ul>
<li>Easy testing with different providers</li>
<li>CI/CD with MockAIService</li>
<li>User choice without rebuilding</li>
</ul>
<h2><a class="anchor" id="autotoc_md1678"></a>
3. Graceful Degradation</h2>
<p>If Ollama/Gemini/Claude unavailable, fall back to MockAIService with clear warnings:</p>
<div class="fragment"><div class="line">⚠️  Ollama unavailable: Cannot connect to http://localhost:11434</div>
<div class="line">   Falling back to MockAIService</div>
<div class="line">   Set YAZE_AI_PROVIDER=ollama or install Ollama to enable LLM</div>
</div><!-- fragment --><h2><a class="anchor" id="autotoc_md1679"></a>
4. System Prompt Engineering</h2>
<p>Comprehensive system prompts include:</p><ul>
<li>Full command catalogue from <code>z3ed-resources.yaml</code></li>
<li>Few-shot examples (proven prompt/command pairs)</li>
<li>Output format requirements (JSON array of strings)</li>
<li>Current ROM context (loaded file, editors open)</li>
</ul>
<p>This improves accuracy from ~60% to &gt;90% for standard tasks.</p>
<h1><a class="anchor" id="autotoc_md1680"></a>
Success Metrics</h1>
<h2><a class="anchor" id="autotoc_md1681"></a>
Phase 1 Complete When:</h2>
<ul>
<li>✅ <code>z3ed agent run</code> works with Ollama end-to-end</li>
<li>✅ Health checks report clear errors</li>
<li>✅ Fallback to MockAIService is transparent</li>
<li>✅ Test script passes on macOS</li>
</ul>
<h2><a class="anchor" id="autotoc_md1682"></a>
Full Integration Complete When:</h2>
<ul>
<li>✅ All three providers (Ollama, Gemini, Claude) work</li>
<li>✅ Command accuracy &gt;90% on standard prompts</li>
<li>✅ Documentation guides users through setup</li>
<li>✅ At least one community member validates workflow</li>
</ul>
<h1><a class="anchor" id="autotoc_md1683"></a>
Known Limitations</h1>
<h2><a class="anchor" id="autotoc_md1684"></a>
Current Implementation</h2>
<ul>
<li><code>MockAIService</code> returns hardcoded test commands</li>
<li>No real LLM integration yet</li>
<li>Limited to simple test cases</li>
</ul>
<h2><a class="anchor" id="autotoc_md1685"></a>
After LLM Integration</h2>
<ul>
<li><b>Model hallucination</b>: LLMs may generate invalid commands<ul>
<li>Mitigation: Validation layer + resource catalogue</li>
</ul>
</li>
<li><b>API rate limits</b>: Remote providers (Gemini/Claude) have limits<ul>
<li>Mitigation: Response caching + local Ollama option</li>
</ul>
</li>
<li><b>Cost</b>: API calls cost money (Gemini ~$0.10/million tokens)<ul>
<li>Mitigation: Ollama is free + cache responses</li>
</ul>
</li>
</ul>
<h1><a class="anchor" id="autotoc_md1686"></a>
FAQ</h1>
<h2><a class="anchor" id="autotoc_md1687"></a>
Why Ollama first?</h2>
<ul>
<li><b>No API keys</b>: Works out of the box</li>
<li><b>Privacy</b>: All processing local</li>
<li><b>Speed</b>: No network latency</li>
<li><b>Cost</b>: Zero dollars</li>
<li><b>Testing</b>: No rate limits</li>
</ul>
<h2><a class="anchor" id="autotoc_md1688"></a>
Why not OpenAI?</h2>
<ul>
<li>Cost (GPT-4 is expensive)</li>
<li>Rate limits (strict for free tier)</li>
<li>Not local (privacy concerns for ROM hackers)</li>
<li>Ollama + Gemini cover both local and remote use cases</li>
</ul>
<h2><a class="anchor" id="autotoc_md1689"></a>
Can I use multiple providers?</h2>
<p>Yes! Set <code>YAZE_AI_PROVIDER</code> per command:</p>
<div class="fragment"><div class="line">YAZE_AI_PROVIDER=ollama z3ed agent run --prompt &quot;Quick test&quot;</div>
<div class="line">YAZE_AI_PROVIDER=gemini z3ed agent run --prompt &quot;Complex task&quot;</div>
</div><!-- fragment --><h2><a class="anchor" id="autotoc_md1690"></a>
What if I don't want to use AI?</h2>
<p>The CLI still works without LLM integration:</p>
<div class="fragment"><div class="line"># Direct command execution (no LLM)</div>
<div class="line">z3ed rom validate --rom zelda3.sfc</div>
<div class="line">z3ed palette export --group sprites --id soldier --to output.pal</div>
</div><!-- fragment --><p>AI is <b>optional</b> and additive.</p>
<h1><a class="anchor" id="autotoc_md1691"></a>
Next Steps</h1>
<h2><a class="anchor" id="autotoc_md1692"></a>
For @scawful (Project Owner)</h2>
<ol type="1">
<li><b>Review this plan</b>: Confirm priority shift from IT-10 to LLM integration</li>
<li><b>Decide on Phase 1</b>: Start Ollama implementation (~4-6 hours)</li>
<li><b>Allocate time</b>: Schedule implementation over next 1-2 weeks</li>
<li><b>Test setup</b>: Install Ollama and verify it works on your machine</li>
</ol>
<h2><a class="anchor" id="autotoc_md1693"></a>
For Contributors</h2>
<ol type="1">
<li><b>Read the docs</b>: Start with <a class="el" href="../../de/da5/md_docs_2z3ed_2LLM-INTEGRATION-PLAN.html">LLM-INTEGRATION-PLAN.md</a></li>
<li><b>Pick a phase</b>: Phase 1 (Ollama) is the highest priority</li>
<li><b>Follow checklist</b>: Use <a class="el" href="../../d2/d74/md_docs_2z3ed_2LLM-IMPLEMENTATION-CHECKLIST.html">LLM-IMPLEMENTATION-CHECKLIST.md</a></li>
<li><b>Submit PR</b>: Include tests + documentation updates</li>
</ol>
<h2><a class="anchor" id="autotoc_md1694"></a>
For Users (Future)</h2>
<ol type="1">
<li><b>Wait for release</b>: This is in development</li>
<li><b>Install Ollama</b>: Get ready for local LLM support</li>
<li><b>Follow setup guide</b>: Will be in <code>AI-SERVICE-SETUP.md</code> (coming soon)</li>
</ol>
<h1><a class="anchor" id="autotoc_md1695"></a>
Timeline</h1>
<p><b>Week 1 (Oct 7-11, 2025)</b>: Phase 1 (Ollama) <br  />
 <b>Week 2 (Oct 14-18, 2025)</b>: Phases 2-4 (Gemini, Claude, Prompting) <br  />
 <b>Week 3 (Oct 21-25, 2025)</b>: Testing, docs, user validation</p>
<p><b>Estimated Total</b>: 12-15 hours of development time</p>
<h1><a class="anchor" id="autotoc_md1696"></a>
Related Documents</h1>
<ul>
<li><b><a class="el" href="../../de/da5/md_docs_2z3ed_2LLM-INTEGRATION-PLAN.html">LLM-INTEGRATION-PLAN.md</a></b> - Complete technical implementation guide</li>
<li><b><a class="el" href="../../d2/d74/md_docs_2z3ed_2LLM-IMPLEMENTATION-CHECKLIST.html">LLM-IMPLEMENTATION-CHECKLIST.md</a></b> - Step-by-step task list</li>
<li><b><a class="el" href="../../d5/dc5/md_docs_2z3ed_2E6-z3ed-cli-design.html">E6-z3ed-cli-design.md</a></b> - Overall architecture</li>
<li><b><a class="el" href="../../df/da9/md_docs_2z3ed_2E6-z3ed-implementation-plan.html">E6-z3ed-implementation-plan.md</a></b> - Project roadmap</li>
</ul>
<h1><a class="anchor" id="autotoc_md1697"></a>
Questions?</h1>
<p>Open an issue or discuss in the project's communication channel. Tag this as "LLM Integration" for visibility.</p>
<hr  />
<p><b>Status</b>: Documentation Complete | Ready to Begin Implementation <br  />
 <b>Next Action</b>: Start Phase 1 (Ollama Integration) using checklist </p>
</div></div><!-- contents -->
</div><!-- PageDoc -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="footer">Generated by <a href="https://www.doxygen.org/index.html"><img class="footer" src="../../doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.8 </li>
  </ul>
</div>
</body>
</html>
